import sys
sys.path.append('.')
import torch
import numpy as np
from envs.h1.h1_env import H1Env
import time

print("ğŸ¤– åŠ è½½è®­ç»ƒå¥½çš„H1æœºå™¨äºº...")

# åŠ è½½è®­ç»ƒå¥½çš„actoræ¨¡å‹
try:
    actor = torch.load('./experiments/h1/actor.pt', map_location='cpu')
    print("âœ“ æˆåŠŸåŠ è½½ actor.pt")
except:
    try:
        actor = torch.load('./experiments/h1/actor_19999.pt', map_location='cpu')
        print("âœ“ æˆåŠŸåŠ è½½ actor_19999.pt")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        exit()

actor.eval()

# åˆ›å»ºç¯å¢ƒ
print("ğŸ”§ åˆ›å»ºH1ç¯å¢ƒ...")
env = H1Env()

print("ğŸš€ å¼€å§‹è¿è¡Œæœºå™¨äºº! (æŒ‰Ctrl+Cåœæ­¢)")
print("-" * 50)

episode = 1
try:
    while True:
        obs = env.reset()
        total_reward = 0
        steps = 0
        
        print(f"ğŸ“ Episode {episode} å¼€å§‹")
        
        for step in range(1000):  # æœ€å¤š1000æ­¥
            # ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥
            with torch.no_grad():
                obs_tensor = torch.FloatTensor(obs).unsqueeze(0)
                action = actor(obs_tensor).numpy()[0]
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, done, info = env.step(action)
            total_reward += reward
            steps += 1
            
            # æ¸²æŸ“æ˜¾ç¤º
            env.render()
            time.sleep(0.01)  # ç¨å¾®å‡æ…¢é€Ÿåº¦ä»¥ä¾¿è§‚å¯Ÿ
            
            if done:
                break
        
        print(f"âœ… Episode {episode} å®Œæˆ: {steps} æ­¥, å¥–åŠ±: {total_reward:.2f}")
        episode += 1
        time.sleep(1)  # episodeé—´éš”

except KeyboardInterrupt:
    print("\nğŸ›‘ ç”¨æˆ·åœæ­¢è¿è¡Œ")
    
print("ğŸ‘‹ ç¨‹åºç»“æŸ")
